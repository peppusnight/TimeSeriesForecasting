{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "pd.set_option('max_colwidth', 500)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({'font.size': 9})\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from utils import *\n",
    "import xgboost as xgb\n",
    "%matplotlib notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-spain",
   "metadata": {},
   "source": [
    "# 0 - Problem Statement\n",
    "The goal of this notebook is to show possible usage of Random Forest regressor for timeseries forecasting; in the notebook multiple example are given with the usage of a general purpose library.<br>\n",
    "The notebook contains the following sections:\n",
    "\n",
    "1. Introduction to univariate & multivariate timeseries datasets\n",
    "2. Cross validation: two different techniques\n",
    "3. CART regressor on univariate timeseries\n",
    "4. CART on multivariate timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-partition",
   "metadata": {},
   "source": [
    "# 1 - Introduction to univariate & multivariate timeseries datasets\n",
    "A timeseries without covariates is an \"univariate\" timeseries.<br>\n",
    "Here below an example of female births dataset, that is the monthly births across three years. <br>\n",
    "Credits: <br>\n",
    "https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-total-female-births.csv <br>\n",
    "https://machinelearningmastery.com/random-forest-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'daily-total-female-births.csv'\n",
    "# load the dataset\n",
    "series = pd.read_csv(filename, header=0, index_col=0, parse_dates=True)\n",
    "values = series.values\n",
    "\n",
    "# plot dataset\n",
    "ax = series.plot(style='.-')\n",
    "ax.grid()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-destiny",
   "metadata": {},
   "source": [
    "A timeseries with covariates is a multivaraite timeseries.<br>\n",
    "This dataset contains 19 different features such as air temperature, atmospheric pressure, and humidity collected from 2009 to 2016 with 1 records every hour.<br>\n",
    "Credits: <br>https://www.bgc-jena.mpg.de/wetter/ <br>https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip <br>\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'weather_dataset.csv'\n",
    "# load the dataset\n",
    "data = pd.read_csv(filename, header=0, index_col=0, parse_dates=True)\n",
    "\n",
    "# plot some features\n",
    "feat = ['T (degC)', 'p (mbar)', 'rho (g/m**3)', 'T (degC)']\n",
    "data.plot(y=feat,style='-',grid=True,subplots=True)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-resistance",
   "metadata": {},
   "source": [
    "The models in this notebook will make a set of predictions on both datasets based on a window of consecutive samples. <br>\n",
    "\n",
    "The main features of the input windows are:\n",
    "\n",
    "- The width (number of time steps) of the input and label windows. (parameter \"n_in\")\n",
    "- The time offset between them. (parameter \"n_ahead\")\n",
    "- Single-time-step and multi-time-step predictions. (parameter \"single_output\")\n",
    "- Single-output or multi-output predictions. (for multivariate only)\n",
    "\n",
    "This notebook will use the function \"series_to_supervised\" to do the data windowing.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-moisture",
   "metadata": {},
   "source": [
    "<img src=\"figures/TS_exaplained_pw.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-corner",
   "metadata": {},
   "source": [
    "Here below an example of the usage of the \"series_to_supervised\" function.<br>\n",
    "Timestamps till <b>t-1</b> are the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Params START ##############\n",
    "n_in = 6 # Number of \"previous data\" to use as input\n",
    "n_ahead = 4 # Number of step ahead to predict\n",
    "single_output = False # If True, predicts only the last n_ahead value; else it predicts all the values \"in between\"\n",
    "n_out = 1 if single_output else n_ahead # Number of outputs of the model\n",
    "filename = 'daily-total-female-births.csv'\n",
    "############## Params End ##############\n",
    "\n",
    "# load the dataset\n",
    "series = pd.read_csv(filename, header=0, index_col=0)\n",
    "values = series.values\n",
    "\n",
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Params START ##############\n",
    "n_in = 2 # Number of \"previous data\" to use as input\n",
    "n_ahead = 2 # Number of step ahead to predict\n",
    "single_output = True # If True, predicts only the last n_ahead value; else it predicts all the values \"in between\"\n",
    "n_out = 1 if single_output else n_ahead # Number of outputs of the model\n",
    "filename = 'weather_dataset.csv'\n",
    "############## Params End ##############\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(filename, header=0, index_col=0)\n",
    "df = df[['T (degC)', 'p (mbar)', 'rho (g/m**3)', 'T (degC)']]\n",
    "\n",
    "# transform the time series data into supervised learning\n",
    "data = series_to_supervised(df.values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-highway",
   "metadata": {},
   "source": [
    "# 2 - Cross validation: two different techniques\n",
    "The classical k-fold cross validation cannot be used for timeseries problems because the \"shuffling\" of the records can causa data leakage: information from the future will \"leak\" into the current prediction.<br>\n",
    "For this reason, two different cross-validation techniques are applied:\n",
    "\n",
    "- Sliding vs Expanding windows\n",
    "- Walk forward cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-bowling",
   "metadata": {},
   "source": [
    "## 2.1 Sliding vs Examping window\n",
    "The difference between sliding and expanding windows it is in the train dataset dimension: in the sliding window it is fixed, in the expanding window increases with the training. For both techniques the number of splits are specified by the user. <br>\n",
    "Figures credits: https://www.analyticsvidhya.com/blog/2021/06/random-forest-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-mechanism",
   "metadata": {},
   "source": [
    "<img src=\"figures/SlidingExpanding.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-attendance",
   "metadata": {},
   "source": [
    "In this notebook only <b>expanding window</b> will be used since it uses most of the data for the training. <br>\n",
    "Here below an example of the expanding window approach: <br>\n",
    "Dataset credits: https://machinelearningmastery.com/backtest-machine-learning-models-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('sunspots.csv', header=0, index_col=0)\n",
    "X = series.values\n",
    "splits = TimeSeriesSplit(n_splits=3)\n",
    "plt.figure()\n",
    "index = 1\n",
    "for train_index, test_index in splits.split(X):\n",
    "    train = X[train_index][:,0]\n",
    "    test = X[test_index][:,0]\n",
    "    print('Observations: %d' % (len(train) + len(test)))\n",
    "    print('Training Observations: %d' % (len(train)))\n",
    "    print('Testing Observations: %d' % (len(test)))\n",
    "    plt.subplot(3,1,0 + index)\n",
    "    plt.plot(train)\n",
    "    plt.plot([None for i in train] + [x for x in test])\n",
    "    plt.grid()\n",
    "    index += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-shape",
   "metadata": {},
   "source": [
    "## 2.2 Walk forawd cross validation\n",
    "Walk forward cross validation is a particular case of expanding window where the dimension of the test set is of one record only, so the number of splits will be equal to the number of test sample used for cross validation (parameter \"n_test\" for function \"walk_forward_validation\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-detection",
   "metadata": {},
   "source": [
    "<img src=\"figures/splits.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-royal",
   "metadata": {},
   "source": [
    "# 3 - CART regressor on univariate timeseries\n",
    "The main goal of this notebook is to use CART (Classification And Regression Tree) methods for timeseries forecasting. <br>\n",
    "In this section multiple example of usage are presented and, each time a new CART methodology is used, the main parameter are described.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-judges",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> Two naive models are used for performance comparison:\n",
    "- The persistence model which simply predicts based on last seen record.\n",
    "- The mean model which simply predicts the average of the training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-audit",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> the metric used to compare the model are the Mean Absolute Error (MAE) and the Root Mean Square Error (RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-hudson",
   "metadata": {},
   "source": [
    "## 3.1 Univariate Analysis\n",
    "In this section three differnt CART techniques will be described and applied to the univariate case. This case is trivial but it will be used as a reference case for each technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_metrics = pd.DataFrame(data={'Persistence':[float('nan'),float('nan')],\n",
    "                                    'Mean':[float('nan'),float('nan')],\n",
    "                                    'DecisionTree':[float('nan'),float('nan')],\n",
    "                                    'RandomForest':[float('nan'),float('nan')],\n",
    "                                    'GradientBoosting':[float('nan'),float('nan')],\n",
    "                                    'SuperLearner':[float('nan'),float('nan')]},index=['MAE','RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-event",
   "metadata": {},
   "source": [
    "### 3.1.1 - Decision Tree Regressor\n",
    "The Decision Tree Regressor is the first CART used in this notebook. The main parameters of this CART are the following:\n",
    "- \"criterion\": the greedy algorithm based on the CART training process, need a function to decide the best split. The criterion specifies which function to be used.\n",
    "- \"max_depth\": maximum depth of the tree. This parameter controls the maximum depth of the tree to avoid overfitting.\n",
    "- \"min_samples_split\": The minimum number of samples required to split a node.\n",
    "- \"min_samples_leaf\": The minimum number of samples required to be at a leaf node.\n",
    "- \"ccp_alpha\": The tree can be pruned after its growth. To prune the tree a cost associated to the complexity is added in the cost function of the trainig; this parameter regulates the cost associated to the complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-publication",
   "metadata": {},
   "source": [
    "Here below there is example of decision tree usage on univariate timeseries (the female dataset births dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Data Preprocessing Params ##############\n",
    "n_in = 6 # Number of \"previous data\" to use as input\n",
    "n_ahead = 1 # Number of step ahead to predict\n",
    "single_output = True # If True, predicts only the last n_ahead value; else it predicts all the values \"in between\"\n",
    "n_out = 1 if single_output else n_ahead # Number of outputs of the model\n",
    "train_size = 0.8 # Size of the training set\n",
    "n_splits = 5 # Number of splits for cross validation\n",
    "filename = 'daily-total-female-births.csv'\n",
    "############## Data Preprocessing Params ##############\n",
    "\n",
    "# load the dataset\n",
    "series = pd.read_csv(filename, header=0, index_col=0)\n",
    "\n",
    "# Transform the time series data into supervised learning\n",
    "data = series_to_supervised(series.values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "data_train = data.values[0:int(train_size*data.shape[0])]\n",
    "data_test = data.values[int(train_size*data.shape[0]):]\n",
    "testX, testy = data_test[:, :-n_out], data_test[:, -n_out:]\n",
    "                            \n",
    "# Start the training process\n",
    "predictions = list()\n",
    "predictions_persistence = list()\n",
    "predictions_mean = list()\n",
    "y = list()\n",
    "# Split dataset\n",
    "ts_splits = TimeSeriesSplit(n_splits=n_splits)\n",
    "# Step over each split\n",
    "for train_index, val_index in ts_splits.split(data_train):\n",
    "    train = data_train[train_index]\n",
    "    val = data_train[val_index]\n",
    "    \n",
    "    # Split test row into input and output columns\n",
    "    valX, valy = val[:, :-n_out], val[:, -n_out:]\n",
    "    \n",
    "    # transform list into array\n",
    "    train = np.asarray(train)\n",
    "    \n",
    "    # split into input and output columns\n",
    "    trainX, trainy = train[:, :-n_out], train[:, -n_out:]\n",
    "    \n",
    "    # fit model\n",
    "    model = DecisionTreeRegressor(random_state=0)\n",
    "    model.fit(trainX, trainy.flatten())\n",
    "    \n",
    "    # Perform prediction\n",
    "    yhat = model.predict(valX)\n",
    "    \n",
    "    # Use persistence & mean models\n",
    "    predictions_persistence.append(valX[:,-1])\n",
    "    predictions_mean.append(valX.mean(axis=1))\n",
    "    \n",
    "    # store forecast in list of predictions\n",
    "    predictions.append(yhat.flatten())\n",
    "    y.append(valy.flatten())\n",
    "\n",
    "# Refit the model on the entire training dataset\n",
    "model = DecisionTreeRegressor(random_state=0)\n",
    "model.fit(data_train[:, :-n_out], data_train[:, -n_out:])\n",
    "\n",
    "# Estimate prediction error\n",
    "predictions = np.array(predictions).flatten()\n",
    "predictions_persistence = np.array(predictions_persistence).flatten()\n",
    "predictions_mean = np.array(predictions_mean).flatten()\n",
    "y = np.array(y).flatten()\n",
    "print('Decision Tree - training MAE = {:.3f}'.format(mean_absolute_error(y, predictions)))\n",
    "print('Persistence - training MAE = {:.3f}'.format(mean_absolute_error(y, predictions_persistence)))\n",
    "print('Mean - training MAE = {:.3f}'.format(mean_absolute_error(y, predictions_mean)))\n",
    "# Evaluate regressor on test set\n",
    "print('Decision Tree - test MAE = {:.3f}'.format(mean_absolute_error(testy, model.predict(testX))))\n",
    "print('Persistence - test MAE = {:.3f}'.format(mean_absolute_error(testy, testX[:,-1])))\n",
    "print('Mean - test MAE = {:.3f}'.format(mean_absolute_error(testy, testX.mean(axis=1))))\n",
    "print('Decision Tree - test RMSE = {:.3f}'.format(rmse(testy, model.predict(testX))))\n",
    "print('Persistence - test RMSE = {:.3f}'.format(rmse(testy, testX[:,-1])))\n",
    "print('Mean - test RMSE = {:.3f}'.format(rmse(testy, testX.mean(axis=1))))\n",
    "output_metrics.loc['MAE','Persistence'] = mean_absolute_error(testy, testX[:,-1])\n",
    "output_metrics.loc['MAE','Mean'] = mean_absolute_error(testy, testX.mean(axis=1))\n",
    "output_metrics.loc['RMSE','Persistence'] = rmse(testy, testX[:,-1])\n",
    "output_metrics.loc['RMSE','Mean'] = rmse(testy, testX.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-copper",
   "metadata": {},
   "source": [
    "The same training process can be done by using Scikit-learn package <b>GridSearchCV</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=DecisionTreeRegressor(random_state=0), cv=ts_splits, param_grid={}, scoring='neg_mean_absolute_error')\n",
    "gs.fit(data_train[:, :-n_out], data_train[:, -n_out:])\n",
    "print('Decision Tree - training MAE = {:.3f}'.format(abs(gs.cv_results_['mean_test_score'][0])))\n",
    "print('Decision Tree - test MAE = {:.3f}'.format(mean_absolute_error(testy, gs.best_estimator_.predict(testX))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-supply",
   "metadata": {},
   "source": [
    "The <b>GridSearchCV</b> can be also used for <b>hyper-parameters</b> tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_retraining = False\n",
    "gs = GridSearchCV(estimator=DecisionTreeRegressor(random_state=0), cv=ts_splits, \n",
    "                  param_grid={\n",
    "                      'criterion':['mae','mse'],\n",
    "                      'max_depth':[3,10,100,300],\n",
    "                      'min_samples_split': [5,10,100,1000],\n",
    "                      'ccp_alpha': [0,0.0001,0.001,0.01,1]                      \n",
    "                  },\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  verbose = 0, n_jobs=-1)\n",
    "if force_retraining:\n",
    "    gs.fit(data_train[:, :-n_out], data_train[:, -n_out:])\n",
    "    joblib.dump(gs, 'models/Univariate/DecisionTree.pkl')\n",
    "else:\n",
    "    gs = joblib.load('models/Univariate/DecisionTree.pkl')\n",
    "print('Decision Tree - training MAE = {:.3f}'.format(abs(gs.cv_results_['mean_test_score'][0])))\n",
    "print('Decision Tree - test MAE = {:.3f}'.format(mean_absolute_error(testy, gs.best_estimator_.predict(testX))))\n",
    "print('Decision Tree - test RMSE = {:.3f}'.format(rmse(testy, gs.best_estimator_.predict(testX))))\n",
    "gs_res = pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')[['params','mean_test_score']]\n",
    "gs_res.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-webcam",
   "metadata": {},
   "source": [
    "The best model of the above list is the number 2, since it is the \"simplest\" one among the group with best performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-teacher",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 2\n",
    "dt_tuned = DecisionTreeRegressor(random_state=0)\n",
    "dt_tuned.set_params(**gs_res.loc[idx,'params'])\n",
    "dt_tuned.fit(data_train[:, :-n_out], data_train[:, -n_out:])\n",
    "yhat = dt_tuned.predict(testX)\n",
    "def plot_univariate(yhat,label):\n",
    "    plt.figure(figsize=(9,5))\n",
    "    plt.plot(testy,'.-',label='Data')\n",
    "    plt.plot(yhat,'.-',label=label)\n",
    "    plt.plot(testX[:,-1],'.-',label='Persistence model', alpha=0.3)\n",
    "    plt.plot(testX.mean(axis=1),'.-',label='Mean model',alpha=0.3)\n",
    "    plt.legend(frameon=False, loc=0)\n",
    "    plt.grid()\n",
    "plot_univariate(yhat,label='Decision Tree')\n",
    "output_metrics.loc['MAE','DecisionTree'] = mean_absolute_error(testy, dt_tuned.predict(testX))\n",
    "output_metrics.loc['RMSE','DecisionTree'] = rmse(testy, dt_tuned.predict(testX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-creek",
   "metadata": {},
   "source": [
    "### 3.1.2 - Random Forest Regressor\n",
    "The Random Forest Regressor is the second CART used in this notebook. This method combines an ensemble of DecisionTree and weight their output to generate the prediction. This technique allows the applciation a bootstrap operation on the data and the usage of only a portion of the features for each tree; both these features have the goal to mitigate the overfitting. <br>The main parameters of this CART are the following:\n",
    "- \"n_estimator\": number of estimator to be trained by the algorithm.\n",
    "- \"criterion\": the greedy algorithm based on the CART training process, need a function to decide the best split. The criterion specifies which function to be used.\n",
    "- \"max_depth\": maximum depth of the tree. This parameter controls the maximum depth of the tree to avoid overfitting.\n",
    "- \"min_samples_split\": The minimum number of samples required to split a node.\n",
    "- \"min_samples_leaf\": The minimum number of samples required to be at a leaf node.\n",
    "- \"ccp_alpha\": The tree can be pruned after its growth. To prune the tree a cost associated to the complexity is added in the cost function of the trainig; this parameter regulates the cost associated to the complexity.\n",
    "- \"bootstrap\": if True, bootstrap procedure will be applied (always set to True in these examples)\n",
    "- \"max_features\": The number of features to consider when looking for the best split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_retraining = False\n",
    "gs = GridSearchCV(estimator=RandomForestRegressor(random_state=0), cv=ts_splits,\n",
    "                  param_grid={\n",
    "                      'n_estimators': [10, 100, 1000],\n",
    "                      'criterion':['mae'],\n",
    "                      'max_depth':[10,100],\n",
    "                      'min_samples_split': [5, 10, 100, 500],\n",
    "                      'ccp_alpha': [0,0.001]\n",
    "                  },\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  verbose=0, n_jobs=-1)\n",
    "if force_retraining:\n",
    "    gs.fit(data_train[:, :-n_out], data_train[:, -n_out:].ravel())\n",
    "    joblib.dump(gs, 'models/Univariate/RandomForest.pkl')\n",
    "else:\n",
    "    gs = joblib.load('models/Univariate/RandomForest.pkl')\n",
    "print('Random Forest - training MAE = {:.3f}'.format(abs(gs.cv_results_['mean_test_score'][0])))\n",
    "print('Random Forest - test MAE = {:.3f}'.format(mean_absolute_error(testy, gs.best_estimator_.predict(testX))))\n",
    "gs_res = pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')[['params','mean_test_score']]\n",
    "gs_res.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-parallel",
   "metadata": {},
   "source": [
    "The best model of the above list is the number 18, since it is the \"simplest\" one among the group with best performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 18\n",
    "rf_tuned = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "rf_tuned.set_params(**gs_res.loc[idx,'params'])\n",
    "rf_tuned.fit(data_train[:, :-n_out], data_train[:, -n_out:].ravel())\n",
    "yhat = rf_tuned.predict(testX)\n",
    "plot_univariate(yhat,label='Random Forest')\n",
    "output_metrics.loc['MAE','RandomForest'] = mean_absolute_error(testy, rf_tuned.predict(testX))\n",
    "output_metrics.loc['RMSE','RandomForest'] = rmse(testy, rf_tuned.predict(testX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-handbook",
   "metadata": {},
   "source": [
    "### 3.1.3 Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-moscow",
   "metadata": {},
   "source": [
    "The Gradient Boosting Regressor is the third CART used in this notebook. This technique builds an additive model and it allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function.<br> The main parameters of this CART are the following:\n",
    "- \"loss\": the loss function to be optimized.\n",
    "- \"learning_rate\": the learning rate multiplier for each additional tree.\n",
    "- \"subsample\": the fraction of samples to be used for fitting the individual base learners. \n",
    "- \"n_estimator\": number of estimator to be trained by the algorithm.\n",
    "- \"criterion\": the greedy algorithm based on the CART training process, need a function to decide the best split. The criterion specifies which function to be used.\n",
    "- \"max_depth\": maximum depth of the tree. This parameter controls the maximum depth of the tree to avoid overfitting.\n",
    "- \"min_samples_split\": The minimum number of samples required to split a node.\n",
    "- \"min_samples_leaf\": The minimum number of samples required to be at a leaf node.\n",
    "- \"ccp_alpha\": The tree can be pruned after its growth. To prune the tree a cost associated to the complexity is added in the cost function of the trainig; this parameter regulates the cost associated to the complexity.\n",
    "- \"bootstrap\": if True, bootstrap procedure will be applied (always set to True in these examples)\n",
    "- \"max_features\": The number of features to consider when looking for the best split.\n",
    "- \"validation_fraction\" and \"n_iter_no_change\" and \"tol\": Parameters for the early stopping criterion (use validation dataset to evaluate the loss and if it does not decrease stop the training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_retraining = False\n",
    "gs = GridSearchCV(estimator=GradientBoostingRegressor(random_state=0),cv=ts_splits,\n",
    "                  param_grid={\n",
    "                      'loss': ['ls','lad'],\n",
    "                      'n_estimators': [10, 100, 1000],\n",
    "                      'criterion':['mse'],\n",
    "                      'max_depth':[5,10,100],\n",
    "                      'min_samples_split': [5, 10, 30],\n",
    "                      'learning_rate': [0.000001, 0.0001, 0.01, 0.1]\n",
    "                  },\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  verbose=10,n_jobs=-1)\n",
    "if force_retraining:\n",
    "    gs.fit(data_train[:, :-n_out], data_train[:, -n_out:].ravel())\n",
    "    joblib.dump(gs, 'models/Univariate/GradientBoosting.pkl')\n",
    "else:\n",
    "    gs = joblib.load('models/Univariate/GradientBoosting.pkl')\n",
    "print('Gradient Boosting - training MAE = {:.3f}'.format(abs(gs.cv_results_['mean_test_score'][0])))\n",
    "print('Gradient Boosting - test MAE = {:.3f}'.format(mean_absolute_error(testy, gs.best_estimator_.predict(testX))))\n",
    "gs_res = pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')[['params','mean_test_score']]\n",
    "gs_res.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "gb_tuned = GradientBoostingRegressor(random_state=0)\n",
    "gb_tuned.set_params(**gs_res.loc[idx,'params'])\n",
    "gb_tuned.fit(data_train[:, :-n_out], data_train[:, -n_out:].ravel())\n",
    "yhat = gb_tuned.predict(testX)\n",
    "plot_univariate(yhat,label='Gradient Boosting')\n",
    "output_metrics.loc['MAE','GradientBoosting'] = mean_absolute_error(testy, gb_tuned.predict(testX))\n",
    "output_metrics.loc['RMSE','GradientBoosting'] = rmse(testy, gb_tuned.predict(testX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-basis",
   "metadata": {},
   "source": [
    "Very detailed hyper-parameter tuning has been performed on Gradient Boosting algorithm but without success. This CART predicts always a fixed value so suffers of <b>high bias</b> and <b>low variance</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-spell",
   "metadata": {},
   "source": [
    "### 3.1.4 SuperLearner\n",
    "The idea behind the SuperLearner is to <b>combine different regressors</b> and average all the outputs to obtain predicted values. This type of regressor can be useful for a set of well performing models in order to balance out their individual weaknesses. <br>\n",
    "It has been decided to use the following regressors:\n",
    "\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Linear Regression\n",
    "\n",
    "The Gradient Boosting algorithm was not sued because of its poor performances.<br>\n",
    "Another interesting technique is the <b>stacked generalization</b>. This methodology uses a set of models in parallel (SuperLearner) and the output is used as input for a final estimator. This technique is out of scope of this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_retraining = False\n",
    "reg1 = dt_tuned\n",
    "reg2 = rf_tuned\n",
    "reg3 = LinearRegression()\n",
    "ereg = VotingRegressor(estimators=[('dt', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "if force_retraining:\n",
    "    ereg = ereg.fit(data_train[:, :-n_out], data_train[:, -n_out:].ravel())\n",
    "    joblib.dump(ereg, 'models/Univariate/SuperLearner.pkl')\n",
    "else:\n",
    "    ereg = joblib.load('models/Univariate/SuperLearner.pkl')\n",
    "\n",
    "yhat = ereg.predict(testX)\n",
    "plot_univariate(yhat,label='SuperLearner')\n",
    "output_metrics.loc['MAE','SuperLearner'] = mean_absolute_error(testy, ereg.predict(testX))\n",
    "output_metrics.loc['RMSE','SuperLearner'] = rmse(testy, ereg.predict(testX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-error",
   "metadata": {},
   "source": [
    "Finally, the performances of all models are compared together on the <b>entire set</b> (training and test). <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(data.values[:,-n_out:],'.-',label='Data', alpha = 0.5)\n",
    "plt.plot(dt_tuned.predict(data.values[:,:-n_out]),'.-',label='DecisionTree', alpha = 0.5)\n",
    "plt.plot(rf_tuned.predict(data.values[:,:-n_out]),'.-',label='RandomForest', alpha =0.5)\n",
    "plt.plot(ereg.predict(data.values[:,:-n_out]),'.-',label='SuperLearner', alpha = 0.5)\n",
    "plt.legend(frameon=False, loc=0)\n",
    "plt.grid()\n",
    "output_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-fairy",
   "metadata": {},
   "source": [
    "### 3.2 Data Preprocessing Params Tuning\n",
    "All the regressor shown in the 3.1 sections have the data preprocessing parameter fixed.<br>\n",
    "In this section different \"n_in\" (number of \"lags\") values will be used to generate the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_retraining = False\n",
    "############## Data Preprocessing Params ##############\n",
    "n_in_list = [3,6,12,24] # Number of \"previous data\" to use as input\n",
    "n_ahead = 1 # Number of step ahead to predict\n",
    "single_output = True # If True, predicts only the last n_ahead value; else it predicts all the values \"in between\"\n",
    "n_out = 1 if single_output else n_ahead # Number of outputs of the model\n",
    "train_size = 0.8 # Size of the training set\n",
    "n_splits = 3 # Number of splits for cross validation\n",
    "filename = 'daily-total-female-births.csv'\n",
    "############## Data Preprocessing Params ##############\n",
    "\n",
    "output_metrics_preproc = pd.DataFrame(data={'Persistence - 3':[float('nan'),float('nan')]},index=['MAE','RMSE'])\n",
    "\n",
    "for n_in in n_in_list:\n",
    "    print('Testing {}'.format(n_in))\n",
    "    # load the dataset\n",
    "    series = pd.read_csv(filename, header=0, index_col=0)\n",
    "\n",
    "    # Transform the time series data into supervised learning\n",
    "    data = series_to_supervised(series.values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "    data_train = data.values[0:int(train_size*data.shape[0])]\n",
    "    data_test = data.values[int(train_size*data.shape[0]):]\n",
    "    testX, testy = data_test[:, :-n_out], data_test[:, -n_out:]\n",
    "    \n",
    "    # Naive regressors\n",
    "    output_metrics_preproc.loc['MAE','Persistence - {}'.format(n_in)] = mean_absolute_error(testy, testX[:,-1])\n",
    "    output_metrics_preproc.loc['RMSE', 'Persistence - {}'.format(n_in)] = rmse(testy, testX[:,-1])\n",
    "    output_metrics_preproc.loc['MAE','Mean - {}'.format(n_in)] = mean_absolute_error(testy, testX.mean(axis=1))\n",
    "    output_metrics_preproc.loc['RMSE','Mean - {}'.format(n_in)] = rmse(testy, testX.mean(axis=1))\n",
    "    \n",
    "    # Decision Tree\n",
    "    gs_dt = GridSearchCV(estimator=DecisionTreeRegressor(random_state=0), cv=ts_splits, \n",
    "                  param_grid={'criterion':['mae','mse'],\n",
    "                              'max_depth':[3,10,100,300],\n",
    "                              'min_samples_split': [5,10,100,1000],\n",
    "                              'ccp_alpha': [0,0.0001,0.001,0.01,1]\n",
    "                             },\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  verbose = 0, n_jobs=-1)\n",
    "    if force_retraining:\n",
    "        gs_dt.fit(data_train[:, :-n_out], data_train[:, -n_out:])\n",
    "        joblib.dump(gs_dt, 'models/Univariate/n_in_tuning/DecisionTree_nin_{}.pkl'.format(n_in))\n",
    "    else:\n",
    "        gs_dt = joblib.load('models/Univariate/n_in_tuning/DecisionTree_nin_{}.pkl'.format(n_in))\n",
    "    print('DecisionTree on {} tuned!'.format(n_in))    \n",
    "    yhat = gs_dt.best_estimator_.predict(testX)\n",
    "    output_metrics_preproc.loc['MAE','Decision Tree - {}'.format(n_in)] = mean_absolute_error(testy, yhat)\n",
    "    output_metrics_preproc.loc['RMSE','Decision Tree - {}'.format(n_in)] = rmse(testy, yhat)\n",
    "    \n",
    "    # Random Forest\n",
    "    gs_rf = GridSearchCV(estimator=RandomForestRegressor(random_state=0), cv=ts_splits,\n",
    "                  param_grid={\n",
    "                      'n_estimators': [10, 100, 1000],\n",
    "                      'criterion':['mae'],\n",
    "                      'max_depth':[10,100],\n",
    "                      'min_samples_split': [5, 10, 100, 500],\n",
    "                      'ccp_alpha': [0,0.001]\n",
    "                  },\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  verbose=0, n_jobs=-1)\n",
    "    \n",
    "    if force_retraining:\n",
    "        gs_rf.fit(data_train[:, :-n_out], data_train[:, -n_out:].ravel())\n",
    "        joblib.dump(gs_rf, 'models/Univariate/n_in_tuning/RandomForest_nin_{}.pkl'.format(n_in))\n",
    "    else:\n",
    "        gs_rf = joblib.load('models/Univariate/n_in_tuning/RandomForest_nin_{}.pkl'.format(n_in))\n",
    "    print('RandomForest on {} tuned!'.format(n_in))    \n",
    "    yhat = gs_rf.best_estimator_.predict(testX)\n",
    "    output_metrics_preproc.loc['MAE','Random Forest - {}'.format(n_in)] = mean_absolute_error(testy, yhat)\n",
    "    output_metrics_preproc.loc['RMSE','Random Forest - {}'.format(n_in)] = rmse(testy, yhat)\n",
    "    \n",
    "    # Gradient Boosting\n",
    "    gs_gb = GridSearchCV(estimator=GradientBoostingRegressor(random_state=0),cv=ts_splits,\n",
    "                  param_grid={\n",
    "                      'loss': ['ls','lad'],\n",
    "                      'n_estimators': [10, 100, 1000],\n",
    "                      'criterion':['mse'],\n",
    "                      'max_depth':[5,10,100],\n",
    "                      'min_samples_split': [5, 10, 30],\n",
    "                      'learning_rate': [0.000001, 0.01]\n",
    "                  },\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  verbose=0,n_jobs=-1)\n",
    "    if force_retraining:\n",
    "        gs_gb.fit(data_train[:, :-n_out], data_train[:, -n_out:].ravel())\n",
    "        joblib.dump(gs_gb, 'models/Univariate/n_in_tuning/GradientBoosting_nin_{}.pkl'.format(n_in))\n",
    "    else:\n",
    "        gs_gb = joblib.load('models/Univariate/n_in_tuning/GradientBoosting_nin_{}.pkl'.format(n_in))\n",
    "    print('GradientBoosting on {} tuned!'.format(n_in))   \n",
    "    yhat = gs_gb.best_estimator_.predict(testX)\n",
    "    output_metrics_preproc.loc['MAE','Gradient Boosting - {}'.format(n_in)] = mean_absolute_error(testy, yhat)\n",
    "    output_metrics_preproc.loc['RMSE','Gradient Boosting - {}'.format(n_in)] = rmse(testy, yhat)\n",
    "    \n",
    "    # Super Learner\n",
    "    reg1 = gs_dt.best_estimator_\n",
    "    reg2 = gs_rf.best_estimator_\n",
    "    reg3 = LinearRegression()\n",
    "    ereg = VotingRegressor(estimators=[('dt', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "    if force_retraining:\n",
    "        ereg = ereg.fit(data_train[:, :-n_out], data_train[:, -n_out:].ravel())\n",
    "        joblib.dump(ereg, 'models/Univariate/n_in_tuning/SuperLearner_nin_{}.pkl'.format(n_in))\n",
    "    else:\n",
    "        ereg = joblib.load('models/Univariate/n_in_tuning/SuperLearner_nin_{}.pkl'.format(n_in))\n",
    "    print('SuperLearner on {} tuned!'.format(n_in)) \n",
    "    yhat = ereg.predict(testX)\n",
    "    output_metrics_preproc.loc['MAE','SuperLearner - {}'.format(n_in)] = mean_absolute_error(testy, yhat)\n",
    "    output_metrics_preproc.loc['RMSE','SuperLearner - {}'.format(n_in)] = rmse(testy, yhat) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_metrics_preproc.T.sort_values(by=['MAE','RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt = joblib.load('models/Univariate/n_in_tuning/DecisionTree_nin_24.pkl')\n",
    "yhat = gs_dt.best_estimator_.predict(data.values[:,:-n_out])\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(data.values[:,-n_out:],'.-',label='Data')\n",
    "plt.plot(yhat,'.-',label='Best Decision Tree')\n",
    "plt.legend(frameon=False, loc=0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-salmon",
   "metadata": {},
   "source": [
    "# 4 - Multivariate Analysis\n",
    "This section will show the usage of CART models on a multivariate dataset. <br>\n",
    "This dataset contains 19 different features such as air temperature, atmospheric pressure, and humidity collected from 2009 to 2016 with 1 records every hour. A complete <b>dataset analysis and feature engineering</b> can be found in the TensorFlow credits; for the sake of brevity, it will not be reported here. <br>\n",
    "The goal is to <b>predict the air temperature</b> based on multiple features. Particularly interesting is the feature engineering on daily and yearly dependence:\n",
    "\n",
    "- Two continuous variables (sine and cosine) will represent the time of the day and the time of the year. The usage of sine and cosine ensures unique values for both timings.\n",
    "\n",
    "\n",
    "Credits: <br>https://www.bgc-jena.mpg.de/wetter/ <br>https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip <br>\n",
    "https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'weather_dataset.csv'\n",
    "# load the dataset\n",
    "df = pd.read_csv(filename, header=0, index_col=0, parse_dates=True)\n",
    "\n",
    "# plot some features\n",
    "feat = ['T (degC)','p (mbar)','Day sin', 'Day cos', 'Year sin','Year cos']\n",
    "df.iloc[0:8761].plot(y=feat,style='-',grid=True,subplots=True, figsize=(8,6))\n",
    "plt.show(block=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-monday",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> Before building any model, two naive models and a linear regression model are defined for performance comparison:\n",
    "- The persistence model which simply predicts based on last seen record.\n",
    "- The mean model which simply predicts the average of the training samples.\n",
    "- Linear model: y = beta*X + alpha\n",
    "\n",
    "<b>NOTE:</b> The dataset has been normalize with a standard scaler (subtract the mean and divide by the standard deviation). CART models do not need the scaling since the splits are calculated one feature at a time but in the next section Lasso regression will be used and it requires (or at least is good practice) to perform the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Data Preprocessing Params ##############\n",
    "n_in = 12 # Number of \"previous data\" to use as input\n",
    "n_ahead = 6 # Number of step ahead to predict\n",
    "single_output = True # If True, predicts only the last n_ahead value; else it predicts all the values \"in between\"\n",
    "n_out = 1 if single_output else n_ahead # Number of outputs of the model\n",
    "train_size = 0.7 # Size of the training set\n",
    "n_splits = 5 # Number of splits for cross validation\n",
    "features_tag = ['Day sin', 'Day cos', 'Year sin','Year cos','p (mbar)','Wx','Wy']\n",
    "target_tag = 'T (degC)'\n",
    "filename = 'weather_dataset.csv'\n",
    "############## Data Preprocessing Params ##############\n",
    "\n",
    "output_multi_metrics = pd.DataFrame(data={'Persistence':[float('nan'),float('nan')],\n",
    "                                    'Mean':[float('nan'),float('nan')],\n",
    "                                    'Linear':[float('nan'),float('nan')],\n",
    "                                    'Lasso':[float('nan'),float('nan')],\n",
    "                                    'DecisionTree':[float('nan'),float('nan')],\n",
    "                                    'RandomForest':[float('nan'),float('nan')],\n",
    "                                    'XGBoost':[float('nan'),float('nan')],\n",
    "                                    'SuperLearner':[float('nan'),float('nan')]},index=['MAE','RMSE'])\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(filename, header=0, index_col=0)\n",
    "\n",
    "# Divide into training and test\n",
    "train_size = int(train_size*df.shape[0])\n",
    "df_train = df[features_tag].iloc[0:train_size]\n",
    "df_test = df[features_tag].iloc[train_size:]\n",
    "\n",
    "# Scale the data\n",
    "train_mean, train_std = df_train.mean(), df_train.std()\n",
    "df_train_normed = (df_train - train_mean) / train_std\n",
    "df_test_normed = (df_test - train_mean) / train_std\n",
    "\n",
    "df_train_normed[target_tag] = df.iloc[0:train_size][target_tag].values\n",
    "df_test_normed[target_tag] = df.iloc[train_size:][target_tag].values\n",
    "\n",
    "# Transform the time series data into supervised learning\n",
    "data_train = series_to_supervised(df_train_normed.values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "data_train_target_only = series_to_supervised(df_train_normed[[target_tag]].values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "X_train, y_train = data_train.values[:,:-1], data_train.values[:,-1]\n",
    "data_test = series_to_supervised(df_test_normed.values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "data_test_target_only = series_to_supervised(df_test_normed[[target_tag]].values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "X_test, y_test = data_test.values[:, :-1], data_test.values[:, -1]\n",
    "\n",
    "print('Train size: {}'.format(data_train.shape))\n",
    "print('Test size: {}'.format(data_test.shape))\n",
    "df_train_normed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-bradford",
   "metadata": {},
   "source": [
    "### Important note:\n",
    "The dimension of the dataset is <b>massive</b> so the training process is very slow; to mitigate this problem, it has been decided to use just 2 years of data for the training process. Another possible solution could have been to resample the data (for example: 1 point every 6 hours) but the goal (in this notebook) is to predict the temeprature 1 hour ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 2*365*24 # number of hours in 2 years\n",
    "# Divide into training and test\n",
    "df_train = df[features_tag].iloc[0:train_size]\n",
    "df_test = df[features_tag].iloc[train_size:]\n",
    "\n",
    "# Scale the data\n",
    "train_mean, train_std = df_train.mean(), df_train.std()\n",
    "df_train_normed = (df_train - train_mean) / train_std\n",
    "df_test_normed = (df_test - train_mean) / train_std\n",
    "\n",
    "df_train_normed[target_tag] = df.iloc[0:train_size][target_tag].values\n",
    "df_test_normed[target_tag] = df.iloc[train_size:][target_tag].values\n",
    "\n",
    "# Transform the time series data into supervised learning\n",
    "data_train = series_to_supervised(df_train_normed.values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "data_train_target_only = series_to_supervised(df_train_normed[[target_tag]].values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "X_train, y_train = data_train.values[:,:-1], data_train.values[:,-1]\n",
    "data_test = series_to_supervised(df_test_normed.values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "data_test_target_only = series_to_supervised(df_test_normed[[target_tag]].values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "X_test, y_test = data_test.values[:, :-1], data_test.values[:, -1]\n",
    "\n",
    "print('Train size: {}'.format(data_train.shape))\n",
    "print('Test size: {}'.format(data_test.shape))\n",
    "df_train_normed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-classification",
   "metadata": {},
   "source": [
    "As stated before, let's inspect the performances of 3 different techniques that will be used as a reference for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_target_only, y_target_only = data_test_target_only.values[:, :-1], data_test_target_only.values[:, -1]\n",
    "\n",
    "y_pers =  X_target_only[:,-1]\n",
    "y_mean =  X_target_only.mean(axis=1)\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_lin = reg.predict(X_test)\n",
    "\n",
    "n_days = 3\n",
    "\n",
    "f, ax = plt.subplots(2,1,sharex=False, figsize=(9,6))\n",
    "ax[0].plot(y_test[0:24*n_days],'.-',label='Temperature')\n",
    "ax[0].plot(y_pers[0:24*n_days],'.-',label='Persistence Model', alpha = 0.5)\n",
    "ax[0].plot(y_mean[0:24*n_days],'.-',label='Mean Model', alpha = 0.5)\n",
    "ax[0].plot(y_lin[0:24*n_days], '.-',label='Linear Model', alpha = 0.5)\n",
    "ax[0].set_title('Zoom on {} days'.format(n_days))\n",
    "ax[0].legend(frameon=False)\n",
    "ax[1].plot(y_test,'.-',label='Temperature')\n",
    "ax[1].plot(y_pers,'.-',label='Persistence Model', alpha = 0.5)\n",
    "ax[1].plot(y_mean,'.-',label='Mean Model', alpha = 0.5)\n",
    "ax[1].plot(y_lin, '.-',label='Linear Model', alpha = 0.5)\n",
    "ax[1].set_title('Entire dataset')\n",
    "ax[0].set_ylabel('T [degC]')\n",
    "ax[1].set_ylabel('T [degC]')\n",
    "ax[1].set_xlabel('Time')\n",
    "for a in ax: a.grid(True);\n",
    "\n",
    "print('Persistence - test MAE = {:.3f}'.format(mean_absolute_error(y_test, y_pers)))\n",
    "print('Mean - test MAE = {:.3f}'.format(mean_absolute_error(y_test, y_mean)))\n",
    "print('Linear - test MAE = {:.3f}'.format(mean_absolute_error(y_test, y_lin)))\n",
    "print('Persistence - test RMSE = {:.3f}'.format(rmse(y_test, y_pers)))\n",
    "print('Mean - test RMSE = {:.3f}'.format(rmse(y_test, y_mean)))\n",
    "print('Linear - test RMSE = {:.3f}'.format(rmse(y_test, y_lin)))\n",
    "output_multi_metrics.loc['MAE','Persistence'] = mean_absolute_error(y_test, y_pers)\n",
    "output_multi_metrics.loc['MAE','Mean'] = mean_absolute_error(y_test, y_mean)\n",
    "output_multi_metrics.loc['MAE','Linear'] = mean_absolute_error(y_test, y_lin)\n",
    "output_multi_metrics.loc['RMSE','Persistence'] = rmse(y_test, y_pers)\n",
    "output_multi_metrics.loc['RMSE','Mean'] = rmse(y_test, y_mean)\n",
    "output_multi_metrics.loc['RMSE','Linear'] = rmse(y_test, y_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-diagnosis",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> it is clear from the very high MAE and RMSE (and from second subplots too) that linear regression is having a very unstable behavior in some areas.<br>\n",
    "Let's inspect the coefficients of the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-columbia",
   "metadata": {},
   "source": [
    "It is evident that some coefficients have very high values; since just daily and yearly dependece is considered in this notebook, these coefficients have no reason to be so high.<br>\n",
    "To mitigate this problem, let's apply the <b>Lasso</b> regularization technique and let's compare the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-mining",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lasso = Lasso(alpha=0.1, max_iter=2000).fit(X_train, y_train)\n",
    "y_lasso = reg_lasso.predict(X_test)\n",
    "output_multi_metrics.loc['MAE','Lasso'] = mean_absolute_error(y_test, y_lasso)\n",
    "output_multi_metrics.loc['RMSE','Lasso'] = rmse(y_test, y_lasso)\n",
    "\n",
    "n_days = 3\n",
    "\n",
    "f, ax = plt.subplots(2,1,sharex=False, figsize=(9,6))\n",
    "ax[0].plot(y_test[0:24*n_days],'.-',label='Temperature')\n",
    "ax[0].plot(y_lin[0:24*n_days], '.-',label='Linear Model', alpha = 0.5)\n",
    "ax[0].plot(y_lasso[0:24*n_days], '.-',label='Lasso Model', alpha = 0.5)\n",
    "ax[0].set_title('Zoom on {} days'.format(n_days))\n",
    "ax[0].legend(frameon=False)\n",
    "ax[1].plot(y_test,'.-',label='Temperature')\n",
    "# ax[1].plot(y_lin, '.-',label='Linear Model', alpha = 0.5)\n",
    "ax[1].plot(y_lasso,label='Lasso Model')\n",
    "ax[1].set_title('Entire dataset')\n",
    "ax[0].set_ylabel('T [degC]')\n",
    "ax[1].set_ylabel('T [degC]')\n",
    "ax[1].set_xlabel('Time')\n",
    "for a in ax: a.grid(True);\n",
    "\n",
    "c = pd.DataFrame(data={'Linear coeff': reg.coef_,'Lasso coeff':reg_lasso.coef_}).sort_values(by='Linear coeff', ascending=False)\n",
    "c.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_multi_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-liberia",
   "metadata": {},
   "source": [
    "## 4.1 Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-cholesterol",
   "metadata": {},
   "source": [
    "### 4.1.1 Decision Tree - DA FINIRE\n",
    "As done for the univariate case, a Decision Tree with hyper-parameter tuning has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_retraining = True\n",
    "gs = GridSearchCV(estimator=DecisionTreeRegressor(random_state=0), cv=TimeSeriesSplit(n_splits=n_splits), \n",
    "                  param_grid={\n",
    "                      'criterion':['mae'],\n",
    "                      'max_depth':[5,50,300, 1000],\n",
    "                      'min_samples_split': [10, 100],\n",
    "                      'ccp_alpha': [0,0.001, 0.1, 1]        \n",
    "                  },\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  refit=True,\n",
    "                  verbose = 10, n_jobs=-1)\n",
    "if force_retraining:\n",
    "    gs.fit(X_train, y_train)\n",
    "    joblib.dump(gs, 'models/Multivariate/DecisionTree.pkl')\n",
    "else:\n",
    "    gs = joblib.load('models/Multivariate/DecisionTree.pkl')\n",
    "print('Decision Tree - training MAE = {:.3f}'.format(abs(gs.cv_results_['mean_test_score'][0])))\n",
    "print('Decision Tree - test MAE = {:.3f}'.format(mean_absolute_error(y_test, gs.best_estimator_.predict(X_test))))\n",
    "print('Decision Tree - test RMSE = {:.3f}'.format(rmse(y_test, gs.best_estimator_.predict(X_test))))\n",
    "gs_res = pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')[['params','mean_test_score']]\n",
    "gs_res.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-norfolk",
   "metadata": {},
   "source": [
    "The best model of the above list is the number 3, since it is the \"simplest\" one among the group with best performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "force_retraining = True\n",
    "if force_retraining:\n",
    "    dt_tuned_multi = DecisionTreeRegressor(random_state=0)\n",
    "    dt_tuned_multi.set_params(**gs_res.loc[idx,'params'])\n",
    "    dt_tuned_multi.fit(X_train, y_train)\n",
    "    joblib.dump(dt_tuned_multi, 'models/Multivariate/DecisionTree_finalfit.pkl')\n",
    "else:\n",
    "    dt_tuned_multi = joblib.load('models/Multivariate/DecisionTree_finalfit.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = dt_tuned_multi.predict(X_test)\n",
    "\n",
    "def plot_multivariate(yhat, label, n_days=365):\n",
    "    f, ax = plt.subplots(3,1,sharex=False, figsize=(9,6))\n",
    "    ax[0].plot(y_test[0:24*n_days],'.-',label='Temperature')\n",
    "    ax[0].plot(yhat[0:24*n_days], '.-',label=label, alpha = 0.5)\n",
    "    ax[0].plot(y_lasso[0:24*n_days], '.-',label='Lasso Model', alpha = 0.5)\n",
    "    ax[0].set_title('Zoom on {} days'.format(n_days))\n",
    "    ax[0].legend(frameon=False)\n",
    "    ax[1].plot(y_test,'.-',label='Temperature')\n",
    "    ax[1].plot(yhat, '.-',label=label, alpha = 0.5)\n",
    "    ax[1].plot(y_lasso,label='Lasso Model', alpha = 0.5)\n",
    "    ax[1].set_title('Entire dataset')\n",
    "    ax[2].plot(y_test - yhat, '.-',color='C1',label=label)\n",
    "    ax[2].plot(y_test - y_lasso,color='C2',label='Lasso Model')\n",
    "    ax[0].set_ylabel('T [degC]')\n",
    "    ax[1].set_ylabel('T [degC]')\n",
    "    ax[2].set_ylabel('Residuals')\n",
    "    ax[2].set_xlabel('Time')\n",
    "    ax[2]._shared_x_axes.join(ax[2],ax[1])\n",
    "    for a in ax: a.grid(True);\n",
    "plot_multivariate(y_test_hat, label='Decision Tree')\n",
    "output_multi_metrics.loc['MAE','DecisionTree'] = mean_absolute_error(y_test, y_test_hat)\n",
    "output_multi_metrics.loc['RMSE','DecisionTree'] = rmse(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_multi_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-looking",
   "metadata": {},
   "source": [
    "### 4.1.2 Random Forest - DA FINIRE\n",
    "As done for the univariate case, a Random Forest regressor with hyper-parameter tuning has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_retraining = True\n",
    "gs = GridSearchCV(estimator=RandomForestRegressor(random_state=0), cv=TimeSeriesSplit(n_splits=n_splits), \n",
    "                  param_grid={\n",
    "                      'n_estimators': [10, 100, 1000],\n",
    "                      'criterion':['mae'],\n",
    "                      'max_depth':[100,500],\n",
    "                      'max_features': ['auto', 'log2', 0.5, 0.75],\n",
    "                      'min_samples_split': [10, 100]\n",
    "                      'ccp_alpha': [0,0.001,0.1]\n",
    "                  },\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  verbose=10, n_jobs=-1)\n",
    "if force_retraining:\n",
    "    gs.fit(X_train, y_train)\n",
    "    joblib.dump(gs, 'models/Multivariate/RandomForest.pkl')\n",
    "else:\n",
    "    gs = joblib.load('models/Multivariate/RandomForest.pkl')\n",
    "print('RandomForest - training MAE = {:.3f}'.format(abs(gs.cv_results_['mean_test_score'][0])))\n",
    "print('RandomForest - test MAE = {:.3f}'.format(mean_absolute_error(y_test, gs.best_estimator_.predict(X_test))))\n",
    "print('RandomForest - test RMSE = {:.3f}'.format(rmse(y_test, gs.best_estimator_.predict(X_test))))\n",
    "gs_res = pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')[['params','mean_test_score']]\n",
    "gs_res.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-accommodation",
   "metadata": {},
   "source": [
    "spiega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "force_retraining = True\n",
    "if force_retraining:\n",
    "    rf_tuned_multi = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "    rf_tuned_multi.set_params(**gs_res.loc[idx,'params'])\n",
    "    rf_tuned_multi.fit(X_train, y_train)\n",
    "    joblib.dump(rf_tuned_multi, 'models/Multivariate/RandomForest_finalfit.pkl')\n",
    "else:\n",
    "    rf_tuned_multi = joblib.load('models/Multivariate/RandomForest_finalfit.pkl')\n",
    "y_test_hat = rf_tuned_multi.predict(X_test)\n",
    "plot_multivariate(y_test_hat, label='Random Forest')\n",
    "output_multi_metrics.loc['MAE','RandomForest'] = mean_absolute_error(y_test, y_test_hat)\n",
    "output_multi_metrics.loc['RMSE','RandomForest'] = rmse(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_multi_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-story",
   "metadata": {},
   "source": [
    "### 4.1.3 Extreme Gradient Boosting (xgboost) - DA FINIRE\n",
    "In the univariate case, the GradientBoosting algorithm from Scikit Learn has been used. In the multivariate case the Extreme Gradient Boosting algorithm is going to be used because of its proven performances in training time. <br>\n",
    "The main parameters are the following:\n",
    "- \"n_estimator\": number of estimator to be trained by the algorithm.\n",
    "- \"max_depth\": maximum depth of the tree. This parameter controls the maximum depth of the tree to avoid overfitting.\n",
    "- \"learning_rate\": the learning rate multiplier for each additional tree.\n",
    "- \"objective\": scoring metric to be used. Here instead of MAE, MSE will be used.\n",
    "- \"booster\": Specify which booster to use: gbtree, gblinear or dart.\n",
    "- \"tree_method\": euristics to increase training speed.\n",
    "- \"subsample\": the fraction of samples to be used for fitting the individual base learners.\n",
    "- \"colsample_bytree\": the number of features to consider when looking for the best split (smiliar to \"max_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_retraining = True\n",
    "gs = GridSearchCV(estimator=xgb.XGBRegressor(random_state=0), cv=TimeSeriesSplit(n_splits=n_splits), \n",
    "                  param_grid={\n",
    "                      'n_estimators': [10,20],# [10, 100, 1000],\n",
    "                      'max_depth':[10], #[100,500],                      \n",
    "                      'learning_rate': [0.01], # [0.000001, 0.0001, 0.01, 0.1]\n",
    "                      'booster': ['dart'], #['gbtree','gblinear']\n",
    "                      'tree_method': ['approx','hist'], #['auto','approx'],\n",
    "                      'subsample':[0.5], #[0.75,1]\n",
    "                      'colsample_bytree': [0.5] #[0.5, 0.75, 0.95],\n",
    "                  },\n",
    "                  scoring='neg_mean_absolute_error',\n",
    "                  verbose=10, n_jobs=-1)\n",
    "if force_retraining:\n",
    "    gs.fit(X_train, y_train)\n",
    "    joblib.dump(gs, 'models/Multivariate/XGBoost.pkl')\n",
    "else:\n",
    "    gs = joblib.load('models/Multivariate/XGBoost.pkl')\n",
    "print('XGBoost - training MAE = {:.3f}'.format(abs(gs.cv_results_['mean_test_score'][0])))\n",
    "print('XGBoost - test MAE = {:.3f}'.format(mean_absolute_error(y_test, gs.best_estimator_.predict(X_test))))\n",
    "print('XGBoost - test RMSE = {:.3f}'.format(rmse(y_test, gs.best_estimator_.predict(X_test))))\n",
    "gs_res = pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')[['params','mean_test_score']]\n",
    "gs_res.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-customs",
   "metadata": {},
   "source": [
    "spiega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "force_retraining = True\n",
    "if force_retraining:\n",
    "    xgb_tuned_multi = xgb.XGBRegressor(random_state=0, n_jobs=-1)\n",
    "    xgb_tuned_multi.set_params(**gs_res.loc[idx,'params'])\n",
    "    xgb_tuned_multi.fit(X_train, y_train)\n",
    "    joblib.dump(xgb_tuned_multi, 'models/Multivariate/XGBoost_finalfit.pkl')\n",
    "else:\n",
    "    xgb_tuned_multi = joblib.load('models/Multivariate/XGBoost_finalfit.pkl')\n",
    "y_test_hat = xgb_tuned_multi.predict(X_test)\n",
    "plot_multivariate(y_test_hat, label='XGB')\n",
    "output_multi_metrics.loc['MAE','XGBoost'] = mean_absolute_error(y_test, y_test_hat)\n",
    "output_multi_metrics.loc['RMSE','XGBoost'] = rmse(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_multi_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-integer",
   "metadata": {},
   "source": [
    "### 4.1.4 SuperLearner - DA FINIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_retraining = True\n",
    "reg1 = dt_tuned_multi\n",
    "reg2 = rf_tuned_multi\n",
    "reg3 = Lasso(alpha=0.1, max_iter=2000).fit(X_train, y_train)\n",
    "reg4 = xgb_tuned_multi\n",
    "ereg = VotingRegressor(estimators=[('dt', reg1), ('rf', reg2), ('lr', reg3), ('xgb', reg4)])\n",
    "if force_retraining:\n",
    "    ereg = ereg.fit(X_train, y_train)\n",
    "    joblib.dump(ereg, 'models/Multivariate/SuperLearner.pkl')\n",
    "else:\n",
    "    ereg = joblib.load('models/Multivariate/SuperLearner.pkl')\n",
    "\n",
    "y_test_hat = ereg.predict(testX)\n",
    "plot_multivariate(y_test_hat, label='XGB')\n",
    "output_multi_metrics.loc['MAE','SuperLearner'] = mean_absolute_error(y_test, y_test_hat)\n",
    "output_multi_metrics.loc['RMSE','SuperLearner'] = rmse(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_multi_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-marketplace",
   "metadata": {},
   "source": [
    "# 5 - Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-national",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-strap",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-payment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-compression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############## Params START ##############\n",
    "# n_in = 6 # Number of \"previous data\" to use as input\n",
    "# n_ahead = 1 # Number of step ahead to predict\n",
    "# single_output = True # If True, predicts only the last n_ahead value; else it predicts all the values \"in between\"\n",
    "# n_out = 1 if single_output else n_ahead # Number of outputs of the model\n",
    "# train_size = 0.8 # Size of the training set\n",
    "# n_splits = 5 # Number of splits for cross validation\n",
    "# filename = 'sunspots.csv'\n",
    "# ############## Params End ##############\n",
    "\n",
    "# # load the dataset\n",
    "# series = pd.read_csv(filename, header=0, index_col=0)\n",
    "\n",
    "# # Transform the time series data into supervised learning\n",
    "# data = series_to_supervised(series.values, n_in=n_in, n_out=n_ahead, single_output=single_output)\n",
    "# data_train = data.values[0:int(train_size*data.shape[0])]\n",
    "# data_test = data.values[int(train_size*data.shape[0]):]\n",
    "\n",
    "# gs = GridSearchCV(estimator=model, cv=ts_splits, \n",
    "#                   param_grid={\n",
    "#                       'criterion':['mae','mse'],\n",
    "#                       'max_depth':[3],\n",
    "#                       'min_samples_split': [5],\n",
    "#                       'ccp_alpha': [0,1]                      \n",
    "#                   },\n",
    "#                   scoring='neg_mean_absolute_error')\n",
    "# gs.fit(data_train[:, :-n_out], data_train[:, -n_out:])\n",
    "# print('Decision Tree - training MAE = {:.3f}'.format(abs(gs.cv_results_['mean_test_score'][0])))\n",
    "# print('Decision Tree - test MAE = {:.3f}'.format(mean_absolute_error(testy, gs.best_estimator_.predict(testX))))\n",
    "# gs_res = pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')[['params','mean_test_score']]\n",
    "# gs_res.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-rogers",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
